{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenates non cloud and cloud tsv files, adds either 1 or 0 to addended 'Cloud' column, concatenates files in single database\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def concatenate_clouds(indir=r\"U:\\Training_Data\\Cloud_Pixels\", outfile = r\"U:\\Training_Data\\Cloud_Pixels\\Cloud_Pixels.txt\"):\n",
    "    os.chdir(indir)\n",
    "    fileList = glob.glob('*.txt')\n",
    "    dfList = []\n",
    "    \n",
    "    for filename in fileList:\n",
    "        print(filename)\n",
    "        df = pd.read_csv(filename, delimiter='\\s+')\n",
    "        dfList.append(df)\n",
    "        \n",
    "    concatDf = pd.concat(dfList,axis=0)\n",
    "    concatDf.to_csv(outfile,index=None)\n",
    "    \n",
    "concatenate_clouds()\n",
    "\n",
    "def concatenate_non_clouds(indir=r\"U:\\Training_Data\\Non_Cloud_Pixels\", outfile = r\"U:\\Training_Data\\Non_Cloud_Pixels\\Non_Cloud_Pixels.txt\"):\n",
    "    os.chdir(indir)\n",
    "    fileList = glob.glob('*.txt')\n",
    "    dfList = []\n",
    "    \n",
    "    for filename in fileList:\n",
    "        print(filename)\n",
    "        df = pd.read_csv(filename, delimiter='\\s+')\n",
    "        dfList.append(df)\n",
    "        \n",
    "    concatDf = pd.concat(dfList,axis=0)\n",
    "    concatDf.to_csv(outfile,index=None)\n",
    "    \n",
    "concatenate_non_clouds()\n",
    "\n",
    "with open(r'U:\\Training_Data\\Cloud_Pixels\\Cloud_Pixels.txt','r') as f_in:\n",
    "    with open(r'U:\\Training_Data\\Imagery_Pixels\\Cloud_db.txt', 'w') as f_out:\n",
    "        writer = csv.writer(f_out, delimiter=',', lineterminator='\\n')\n",
    "        reader = csv.reader(f_in, delimiter=',')\n",
    "\n",
    "        result = []\n",
    "        # read headers\n",
    "        row = next(reader)\n",
    "        # add new header to list of headers\n",
    "        row.append('Class')\n",
    "        result.append(row)\n",
    "\n",
    "        for row in reader:\n",
    "            # add new column values\n",
    "            row.append(1)\n",
    "            result.append(row)\n",
    "\n",
    "        writer.writerows(result)\n",
    "\n",
    "with open(r'U:\\Training_Data\\Non_Cloud_Pixels\\Non_Cloud_Pixels.txt','r') as f_in:\n",
    "    with open(r'U:\\Training_Data\\Imagery_Pixels\\Non_Cloud_db.txt', 'w') as f_out:\n",
    "        writer = csv.writer(f_out, delimiter=',', lineterminator='\\n')\n",
    "        reader = csv.reader(f_in, delimiter=',')\n",
    "\n",
    "        result = []\n",
    "        # read headers\n",
    "        row = next(reader)\n",
    "        # add new header to list of headers\n",
    "        row.append('Class')\n",
    "        result.append(row)\n",
    "\n",
    "        for row in reader:\n",
    "            # add new column values\n",
    "            row.append(0)\n",
    "            result.append(row)\n",
    "\n",
    "        writer.writerows(result)\n",
    "        \n",
    "\n",
    "def concatenate_dbs(indir=\"U:\\Training_Data\\Imagery_Pixels\", outfile = \"U:\\Training_Data\\Pixel_database\\Pixel_Database.txt\"):\n",
    "    os.chdir(indir)\n",
    "    fileList = glob.glob('*db.txt')\n",
    "    dfList = []\n",
    "    \n",
    "    for filename in fileList:\n",
    "        print(filename)\n",
    "        df = pd.read_csv(filename, delimiter=',')\n",
    "        dfList.append(df)\n",
    "        \n",
    "    concatDf = pd.concat(dfList,axis=0)\n",
    "    concatDf.to_csv(outfile,index=None)\n",
    "    \n",
    "concatenate_dbs()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>band_3</th>\n",
       "      <th>band_4</th>\n",
       "      <th>band_5</th>\n",
       "      <th>band_6</th>\n",
       "      <th>band_7</th>\n",
       "      <th>band_8</th>\n",
       "      <th>band_9</th>\n",
       "      <th>band_10</th>\n",
       "      <th>band_11</th>\n",
       "      <th>band_12</th>\n",
       "      <th>band_13</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3437</td>\n",
       "      <td>3911</td>\n",
       "      <td>3907</td>\n",
       "      <td>4212</td>\n",
       "      <td>4107</td>\n",
       "      <td>4372</td>\n",
       "      <td>4873</td>\n",
       "      <td>5528</td>\n",
       "      <td>5516</td>\n",
       "      <td>2563</td>\n",
       "      <td>202</td>\n",
       "      <td>5159</td>\n",
       "      <td>4427</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3398</td>\n",
       "      <td>3982</td>\n",
       "      <td>3886</td>\n",
       "      <td>4444</td>\n",
       "      <td>4352</td>\n",
       "      <td>4385</td>\n",
       "      <td>4722</td>\n",
       "      <td>5582</td>\n",
       "      <td>5323</td>\n",
       "      <td>2524</td>\n",
       "      <td>197</td>\n",
       "      <td>5222</td>\n",
       "      <td>4229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3335</td>\n",
       "      <td>3653</td>\n",
       "      <td>3830</td>\n",
       "      <td>4444</td>\n",
       "      <td>4506</td>\n",
       "      <td>4603</td>\n",
       "      <td>4763</td>\n",
       "      <td>5404</td>\n",
       "      <td>5263</td>\n",
       "      <td>2453</td>\n",
       "      <td>191</td>\n",
       "      <td>5408</td>\n",
       "      <td>4190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3221</td>\n",
       "      <td>3399</td>\n",
       "      <td>3730</td>\n",
       "      <td>4347</td>\n",
       "      <td>4388</td>\n",
       "      <td>4632</td>\n",
       "      <td>4882</td>\n",
       "      <td>5073</td>\n",
       "      <td>5277</td>\n",
       "      <td>2322</td>\n",
       "      <td>184</td>\n",
       "      <td>5510</td>\n",
       "      <td>4199</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3083</td>\n",
       "      <td>3666</td>\n",
       "      <td>3728</td>\n",
       "      <td>4328</td>\n",
       "      <td>4116</td>\n",
       "      <td>4259</td>\n",
       "      <td>4615</td>\n",
       "      <td>5019</td>\n",
       "      <td>5125</td>\n",
       "      <td>2159</td>\n",
       "      <td>177</td>\n",
       "      <td>5313</td>\n",
       "      <td>4108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   band_1  band_2  band_3  band_4  band_5  band_6  band_7  band_8  band_9  \\\n",
       "0    3437    3911    3907    4212    4107    4372    4873    5528    5516   \n",
       "1    3398    3982    3886    4444    4352    4385    4722    5582    5323   \n",
       "2    3335    3653    3830    4444    4506    4603    4763    5404    5263   \n",
       "3    3221    3399    3730    4347    4388    4632    4882    5073    5277   \n",
       "4    3083    3666    3728    4328    4116    4259    4615    5019    5125   \n",
       "\n",
       "   band_10  band_11  band_12  band_13  Class  \n",
       "0     2563      202     5159     4427      1  \n",
       "1     2524      197     5222     4229      1  \n",
       "2     2453      191     5408     4190      1  \n",
       "3     2322      184     5510     4199      1  \n",
       "4     2159      177     5313     4108      1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('U:\\Training_Data\\Pixel_database\\Pixel_Database.txt', delimiter= ',')\n",
    "\n",
    "#pixel_db = df[['B1','B2','B3','B4','B5','B6','B7','B8','B8A','B9','B10','B11','B12','Class']]\n",
    "pixel_db = df[['band_1','band_2','band_3','band_4','band_5','band_6','band_7','band_8','band_9','band_10','band_11','band_12','band_13','Class']]\n",
    "\n",
    "\n",
    "pixel_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pixel_db['Class']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat = to_categorical(y)\n",
    "y_cat[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbrown\\AppData\\Local\\conda\\conda\\envs\\neural2\\lib\\site-packages\\pandas\\core\\generic.py:5208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>band_3</th>\n",
       "      <th>band_4</th>\n",
       "      <th>band_5</th>\n",
       "      <th>band_6</th>\n",
       "      <th>band_7</th>\n",
       "      <th>band_8</th>\n",
       "      <th>band_9</th>\n",
       "      <th>band_10</th>\n",
       "      <th>band_11</th>\n",
       "      <th>band_12</th>\n",
       "      <th>band_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.3437</td>\n",
       "      <td>0.3911</td>\n",
       "      <td>0.3907</td>\n",
       "      <td>0.4212</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.4372</td>\n",
       "      <td>0.4873</td>\n",
       "      <td>0.5528</td>\n",
       "      <td>0.5516</td>\n",
       "      <td>0.2563</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.5159</td>\n",
       "      <td>0.4427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.3398</td>\n",
       "      <td>0.3982</td>\n",
       "      <td>0.3886</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.4352</td>\n",
       "      <td>0.4385</td>\n",
       "      <td>0.4722</td>\n",
       "      <td>0.5582</td>\n",
       "      <td>0.5323</td>\n",
       "      <td>0.2524</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>0.4229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.3335</td>\n",
       "      <td>0.3653</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.4506</td>\n",
       "      <td>0.4603</td>\n",
       "      <td>0.4763</td>\n",
       "      <td>0.5404</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.2453</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.5408</td>\n",
       "      <td>0.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.3221</td>\n",
       "      <td>0.3399</td>\n",
       "      <td>0.3730</td>\n",
       "      <td>0.4347</td>\n",
       "      <td>0.4388</td>\n",
       "      <td>0.4632</td>\n",
       "      <td>0.4882</td>\n",
       "      <td>0.5073</td>\n",
       "      <td>0.5277</td>\n",
       "      <td>0.2322</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.5510</td>\n",
       "      <td>0.4199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.3083</td>\n",
       "      <td>0.3666</td>\n",
       "      <td>0.3728</td>\n",
       "      <td>0.4328</td>\n",
       "      <td>0.4116</td>\n",
       "      <td>0.4259</td>\n",
       "      <td>0.4615</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>0.2159</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.5313</td>\n",
       "      <td>0.4108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   band_1  band_2  band_3  band_4  band_5  band_6  band_7  band_8  band_9  \\\n",
       "0  0.3437  0.3911  0.3907  0.4212  0.4107  0.4372  0.4873  0.5528  0.5516   \n",
       "1  0.3398  0.3982  0.3886  0.4444  0.4352  0.4385  0.4722  0.5582  0.5323   \n",
       "2  0.3335  0.3653  0.3830  0.4444  0.4506  0.4603  0.4763  0.5404  0.5263   \n",
       "3  0.3221  0.3399  0.3730  0.4347  0.4388  0.4632  0.4882  0.5073  0.5277   \n",
       "4  0.3083  0.3666  0.3728  0.4328  0.4116  0.4259  0.4615  0.5019  0.5125   \n",
       "\n",
       "   band_10  band_11  band_12  band_13  \n",
       "0   0.2563   0.0202   0.5159   0.4427  \n",
       "1   0.2524   0.0197   0.5222   0.4229  \n",
       "2   0.2453   0.0191   0.5408   0.4190  \n",
       "3   0.2322   0.0184   0.5510   0.4199  \n",
       "4   0.2159   0.0177   0.5313   0.4108  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pixel_db[['band_1','band_2','band_3','band_4','band_5','band_6','band_7','band_8','band_9','band_10','band_11','band_12','band_13']]\n",
    "X.band_1 *= .0001\n",
    "X.band_2 *= .0001\n",
    "X.band_3 *= .0001\n",
    "X.band_4 *= .0001\n",
    "X.band_5 *= .0001\n",
    "X.band_6 *= .0001\n",
    "X.band_7 *= .0001\n",
    "X.band_8 *= .0001\n",
    "X.band_9 *= .0001\n",
    "X.band_10 *= .0001\n",
    "X.band_11 *= .0001\n",
    "X.band_12 *= .0001\n",
    "X.band_13 *= .0001\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y_cat,\n",
    "                                                    test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(np.ravel(y_train,order='C')),\n",
    "                                                 np.ravel(y_train,order='C'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Embedding\n",
    "from keras.optimizers import Adamax, SGD, Adadelta\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Dropout(0.2, input_shape=(13,)))\n",
    "model.add(Dense(64, input_shape=(13,),kernel_initializer='uniform', activation='softmax'))\n",
    "model.add(Dropout(0.1))\n",
    "#model.add(Dense(13, input_shape=(13,), kernel_initializer='uniform', activation='softmax'))\n",
    "model.add(Dense(64, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "model.add(Dense(64, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "model.add(Dense(64, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "model.add(Dense(64, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "\n",
    "#model.compile(loss='binary_crossentropy',\n",
    "              #optimizer='rmsprop',\n",
    "              #metrics=['accuracy'])\n",
    "model.compile(Adamax(lr=0.01),\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 282734 samples, validate on 14881 samples\n",
      "Epoch 1/14\n",
      "282734/282734 [==============================] - 9s 33us/step - loss: 0.2975 - acc: 0.8915 - val_loss: 0.4379 - val_acc: 0.8411\n",
      "Epoch 2/14\n",
      "282734/282734 [==============================] - 9s 32us/step - loss: 0.2394 - acc: 0.9175 - val_loss: 0.5411 - val_acc: 0.8019\n",
      "Epoch 3/14\n",
      "282734/282734 [==============================] - 9s 32us/step - loss: 0.2245 - acc: 0.9240 - val_loss: 0.2855 - val_acc: 0.9072\n",
      "Epoch 4/14\n",
      "282734/282734 [==============================] - 9s 31us/step - loss: 0.2151 - acc: 0.9276 - val_loss: 0.3101 - val_acc: 0.8801\n",
      "Epoch 5/14\n",
      "282734/282734 [==============================] - 9s 33us/step - loss: 0.2090 - acc: 0.9296 - val_loss: 0.3780 - val_acc: 0.8725\n",
      "Epoch 6/14\n",
      "282734/282734 [==============================] - 9s 33us/step - loss: 0.2043 - acc: 0.9310 - val_loss: 0.2701 - val_acc: 0.9094\n",
      "Epoch 7/14\n",
      "282734/282734 [==============================] - 9s 32us/step - loss: 0.1991 - acc: 0.9324 - val_loss: 0.2657 - val_acc: 0.8927\n",
      "Epoch 8/14\n",
      "282734/282734 [==============================] - 9s 32us/step - loss: 0.1939 - acc: 0.9339 - val_loss: 0.4073 - val_acc: 0.8675\n",
      "Epoch 9/14\n",
      "282734/282734 [==============================] - 9s 31us/step - loss: 0.1913 - acc: 0.9347 - val_loss: 0.2817 - val_acc: 0.8998\n",
      "Epoch 10/14\n",
      "282734/282734 [==============================] - 9s 32us/step - loss: 0.1881 - acc: 0.9360 - val_loss: 0.3133 - val_acc: 0.8884\n",
      "Epoch 11/14\n",
      "282734/282734 [==============================] - 9s 32us/step - loss: 0.1856 - acc: 0.9368 - val_loss: 0.4509 - val_acc: 0.8393\n",
      "Epoch 12/14\n",
      "282734/282734 [==============================] - 9s 32us/step - loss: 0.1834 - acc: 0.9376 - val_loss: 0.3170 - val_acc: 0.8866\n",
      "Epoch 13/14\n",
      "282734/282734 [==============================] - 9s 32us/step - loss: 0.1808 - acc: 0.9381 - val_loss: 0.3695 - val_acc: 0.8787\n",
      "Epoch 14/14\n",
      "282734/282734 [==============================] - 9s 32us/step - loss: 0.1785 - acc: 0.9393 - val_loss: 0.3730 - val_acc: 0.8642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ee66d60ba8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y_cat, epochs=14, validation_split=0.05,shuffle=True,class_weight={0:1,1:1.05})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297615/297615 [==============================] - 4s 12us/step\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X,y_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9410782386640458"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('U:\\Training_Data\\Models\\Model_332.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(r'U:\\Training_Data\\Models\\300\\Model_315.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: http://nbviewer.jupyter.org/github/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb\n",
    "# Helper functions for TF Graph visualization\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = bytes(\"<stripped %d bytes>\"%size, 'utf-8')\n",
    "    return strip_def\n",
    "  \n",
    "def rename_nodes(graph_def, rename_func):\n",
    "    res_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = res_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        n.name = rename_func(n.name)\n",
    "        for i, s in enumerate(n.input):\n",
    "            n.input[i] = rename_func(s) if s[0]!='^' else '^'+rename_func(s[1:])\n",
    "    return res_def\n",
    "  \n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "  \n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:800px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))\n",
    "# Visualizing the network graph. Be sure expand the \"mixed\" nodes to see their \n",
    "# internal structure. We are going to visualize \"Conv2D\" nodes.\n",
    "graph_def = tf.get_default_graph().as_graph_def()\n",
    "tmp_def = rename_nodes(graph_def, lambda s:\"/\".join(s.split('_',1)))\n",
    "show_graph(tmp_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from osgeo import gdal\n",
    "import glob\n",
    "\n",
    "os.chdir(r'U:\\Training_Data\\Training_Images\\T32VMN_20190804')\n",
    "\n",
    "fileList= glob.glob('*B??.jp2')\n",
    "\n",
    "warp_options = gdal.WarpOptions(format=\"GTiff\",resampleAlg=\"cubic\", width=5490, height=5490)\n",
    "\n",
    "for i in fileList:\n",
    "    print(i)\n",
    "    img = gdal.Open(i)\n",
    "    gdal.Warp(str(i[-7:-4]) + '.tif', img, options = warp_options)\n",
    "\n",
    "import sys, os, subprocess\n",
    "sys.path.append(r'C:\\Users\\jbrown\\AppData\\Local\\conda\\conda\\envs\\neural2\\Scripts') \n",
    "gm = os.path.join('C:\\\\','Users','jbrown','AppData','Local','conda','conda','envs','neural2','Scripts','gdal_merge.py')\n",
    "merge_command = [\"python\", gm,'-separate', \"-o\", i[:15]+\".tif\", \"B01.tif\", \"B02.tif\",\"B03.tif\",\"B04.tif\",\n",
    "                 \"B05.tif\",\"B06.tif\",\"B07.tif\",\"B08.tif\",\"B8A.tif\",\"B09.tif\",\"B10.tif\",\"B11.tif\",\"B12.tif\",]\n",
    "subprocess.call(merge_command,shell=True)\n",
    "fileList=''\n",
    "gm=''\n",
    "\n",
    "removeList = glob.glob('B*.tif')\n",
    "for i in removeList:\n",
    "    os.remove(i)\n",
    "    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, os, sys\n",
    "from osgeo import gdal\n",
    "\n",
    "fileList=glob.glob('*B??.tif')\n",
    "\n",
    "\n",
    "for file in fileList:\n",
    "    sys.path.append(r'C:\\Users\\jbrown\\AppData\\Local\\conda\\conda\\envs\\neural\\Scripts') \n",
    "    gm = os.path.join('C:\\\\','Users','jbrown','AppData','Local','conda','conda','envs','neural','Scripts','gdal_calc.py')\n",
    "    merge_command = [\"python\", gm,\"--outfile\", file[0:3]+\"_updated.tif\",'-A',file,\n",
    "                     '--calc','A*0.0001']\n",
    "    subprocess.call(merge_command,shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdal.Translate(destName='B04_updated.tif',srcDS='B04.tif',outputType=gdal.GDT_Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=['x','y','z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "\n",
    "img = gdal.Open('B01.tif')\n",
    "srs = img.GetProjection()\n",
    "geo_transform = img.GetGeoTransform()\n",
    "minx = geo_transform[0]\n",
    "maxy = geo_transform[3]\n",
    "maxx = minx + geo_transform[1] * img.RasterXSize\n",
    "miny = maxy + geo_transform[5] * img.RasterYSize\n",
    "\n",
    "x = list(range(int(minx),int(maxx),20))\n",
    "y = list(range(int(miny),int(maxy),20))\n",
    "\n",
    "df['x']=x\n",
    "df['y']=y\n",
    "df['z']=1\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "\n",
    "img = gdal.Open('B01.tif')\n",
    "srs = img.GetProjection()\n",
    "geo_transform = img.GetGeoTransform()\n",
    "minx = geo_transform[0]\n",
    "maxy = geo_transform[3]\n",
    "maxx = minx + geo_transform[1] * img.RasterXSize\n",
    "miny = maxy + geo_transform[5] * img.RasterYSize\n",
    "\n",
    "gdal.Warp(destNameOrDestDS='test.tif',\n",
    "               srcDSOrSrcDSTab='B01.csv',\n",
    "               width=5490,\n",
    "               height=5490,\n",
    "               format=\"GTiff\",\n",
    "               dstSRS='EPSG:'+srs[-8:-3],\n",
    "               outputBounds=[minx, miny, maxx, maxy]\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#y_pred = model.predict(X_test)\n",
    "test_image = pd.read_csv(r'U:\\Imagery\\T36PYB_Masks\\T36PYB_20180525.txt', delimiter = '\\s+')\n",
    "test_image_bands = test_image[['B1','B2','B3','B4','B5','B6','B7','B8','B8A','B9','B10','B11','B12']]\n",
    "test_image_bands.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t0=time.time()\n",
    "y_pred = model.predict(test_image_bands.values)\n",
    "t1=time.time()\n",
    "total=t1-t0\n",
    "print(total)\n",
    "y_pred[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#y_test_class = np.argmax(y_test, axis=1)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "#y_pred_class = np.rint(y_pred)\n",
    "#y_pred_class.shape\n",
    "y_pred_class[:75]\n",
    "y_pred_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_count = 0\n",
    "non_cloud_count = 0\n",
    "\n",
    "for i in y_pred_class:\n",
    "    if i == 1:\n",
    "        cloud_count += 1\n",
    "    if i == 0:\n",
    "        non_cloud_count += 1\n",
    "        \n",
    "print('Cloud pixel amount: '+ str(cloud_count))\n",
    "print('Non_cloud pixel amount: '+ str(non_cloud_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test_class, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next scripts would take y_pred_class values,\n",
    "#and concatenate them to a csv with the pixel x,y info for that image\n",
    "len(y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = pd.read_csv(r'U:\\Imagery\\T36PYB_Masks\\T36PYB_20180525.txt', delimiter = '\\s+')\n",
    "\n",
    "\n",
    "#final_mask = test_image[['Longitude','Latitude','0','1','2','3']]\n",
    "#test_image = pd.DataFrame(test_image)\n",
    "test_image['Class'] = y_pred_class\n",
    "\n",
    "#final_mask.head()\n",
    "test_image.to_csv(r'U:\\Imagery\\T36PYB_Masks\\T36PYB_Mask5.csv',columns = ['Longitude','Latitude','Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = pd.read_csv('C:\\\\ztdl\\\\Masks\\\\Test_Mask14.csv', delimiter = ',')\n",
    "test_image.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should be same as above\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "df = pd.read_csv('C:\\\\ztdl\\\\Masks\\\\Test_Mask.csv')\n",
    "\n",
    "new_df = df[['Longitude','Latitude','Cloud']]\n",
    "\n",
    "new_df.to_csv('C:\\\\ztdl\\\\Masks\\\\Test_Mask2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "\n",
    "raster = gdal.Open(r'U:\\Training_Data\\Training_Images\\S2B_MSIL1C_20181007T084829_N0206_R107_T35TPF_20181007T124415.SAFE\\GRANULE\\L1C_T35TPF_A008284_20181007T084829\\IMG_DATA\\B01.tif')\n",
    "band = raster.GetRasterBand(1)\n",
    "band.ReadAsArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdal\n",
    "from gdalconst import *\n",
    "import os\n",
    "\n",
    "os.chdir('C:\\\\ztdl\\\\Masks')\n",
    "#gdal_cmd = 'gdal_translate -a_srs ESPG:29100 Test_Mask10.csv Test_Mask10.tif'\n",
    "#subprocess.call(gdal_cmd, shell=True)\n",
    "\n",
    "df = gdal.Open('C:\\\\ztdl\\\\Masks\\\\Test_Mask10.xyz')\n",
    "fmt = \"GTiff\"\n",
    "driver = gdal.GetDriverByName(fmt)\n",
    "driver.Register()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.CreateCopy('C:\\\\ztdl\\\\Masks\\\\Test_Mask10.tif', df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.system('gdal_translate -of GTiff Test_Mask10.xyz Test_Mask10.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.call('gdalinfo --formats',shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv('Test_Mask10.xyz')\n",
    "df[:1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
