{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, glob, sys, subprocess, time, scipy, png, cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images, imsave\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "from osgeo import gdal, gdal_array\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfkeras\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from tensorflow.keras.layers import Lambda, RepeatVector, Reshape\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, ZeroPadding2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, GlobalMaxPool2D\n",
    "from tensorflow.keras.layers import concatenate, add\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam, Adamax, Adadelta, RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "import contextlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR TRAINING IMAGES AND SELF MADE MASKS\n",
    "import os\n",
    "from osgeo import gdal\n",
    "\n",
    "\n",
    "directory = r'U:\\Training_Data\\Training_Images\\Test\\T54SVF_20190314'\n",
    "os.chdir(directory)\n",
    "\n",
    "width = 5490\n",
    "height = 5490\n",
    "tilesize = 549\n",
    "\n",
    "for i in range(0, width, tilesize):\n",
    "    for j in range(0, height, tilesize):\n",
    "        gdal.Translate(destName = str(i)+'_'+str(j)+'_T54SVF.png',\n",
    "                      srcDS = 'T54SVF_20190314.tif',\n",
    "                      bandList = [9,4,3,2],\n",
    "                      srcWin = [i,j,tilesize,tilesize],\n",
    "                      noData = None,\n",
    "                      format = \"PNG\"\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append all filenames in a given directory\n",
    "import os\n",
    " \n",
    "path = r'U:\\Training_Data\\Training_Images\\Test\\T44TLM_20190418\\Raster_Mask'\n",
    "for filename in os.listdir(path):\n",
    "    filename_without_ext = os.path.splitext(filename)[0]\n",
    "    extension = os.path.splitext(filename)[1]\n",
    "    new_file_name = filename_without_ext+\"_T44TLM\" #<--- this will be appended to the end of the filename\n",
    "    new_file_name_with_ext = new_file_name+extension\n",
    "    #print(new_file_name_with_ext)\n",
    "    os.rename(os.path.join(path,filename),os.path.join(path,new_file_name_with_ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "im_width = 512\n",
    "im_height = 512\n",
    "border = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r'U:\\Training_Data\\Training_Images\\Test\\Unet_Train'\n",
    "ids = next(os.walk(train_path))[2] # list of names all images in the given path\n",
    "for i in ids:\n",
    "    if '.xml' in i:\n",
    "        ids.remove(i)\n",
    "\n",
    "try:\n",
    "    ids.remove('Thumbs.db')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"No. of images = \", len(ids))\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(ids), im_height, im_width, 4), dtype=np.float32)\n",
    "y = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm is used to display the progress bar\n",
    "import os\n",
    "os.chdir(r'U:\\Training_Data\\Training_Images\\Test\\Unet_Train')\n",
    "for n, id_ in tqdm_notebook(enumerate(ids), total=len(ids)):\n",
    "    # Load images\n",
    "    #x_img = gdal_array.LoadFile(id_)\n",
    "    img = load_img(id_)\n",
    "    x_img = img_to_array(img)\n",
    "    x_img = resize(x_img, (im_width, im_height, 4), mode = 'edge', preserve_range = True)\n",
    "    # Load masks\n",
    "    mask = img_to_array(load_img(\"Raster_Masks/Split/\"+id_,color_mode='grayscale'))\n",
    "    mask = resize(mask, (im_width, im_height, 1), mode = 'constant', preserve_range = True)\n",
    "    # Save images\n",
    "    X[n] = x_img/255.0\n",
    "    y[n] = mask/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize any randome image along with the mask\n",
    "ix = random.randint(0, len(X))\n",
    "has_mask = y[ix].max() > 0 # cloud indicator\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 15))\n",
    "\n",
    "ax1.imshow(X[ix, ..., 0], cmap = 'gray', interpolation = 'bilinear')\n",
    "if has_mask: # if salt\n",
    "    # draw a boundary(contour) in the original image separating cloud and non-cloud areas\n",
    "    ax1.contour(y[ix].squeeze(), colors = 'k', linewidths = 5, levels = [0.5])\n",
    "ax1.set_title('Image')\n",
    "\n",
    "ax2.imshow(y[ix].squeeze(), cmap = 'gray', interpolation = 'bilinear')\n",
    "ax2.set_title('Mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_block4(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #third layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    #fourth layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv2d_block5(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #third layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    #fourth layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #fifth layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "  \n",
    "def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n",
    "# Encoder\n",
    "    c1 = conv2d_block5(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "\n",
    "    c2 = conv2d_block5(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = conv2d_block5(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = conv2d_block4(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "\n",
    "    c5 = conv2d_block4(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    # Decoder\n",
    "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block4(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block5(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block5(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block5(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfkeras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input((im_height, im_width, 4), name='img')\n",
    "model = get_unet(input_img, n_filters=16, dropout=0.1, batchnorm=True)\n",
    "model.compile(optimizer=RMSprop(lr=0.001), loss='poisson', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "os.chdir(r'U:\\Training_Data\\Training_Images\\Test')\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "with open('modelsummary.txt', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(patience=10, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.000001, verbose=1),\n",
    "    ModelCheckpoint(r'U:\\Training_Data\\CNN_Models\\Model_116.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t3 = time.time()\n",
    "results = model.fit(X, y, batch_size=1, epochs=4,validation_split=0.1,shuffle=True)\n",
    "t4 = time.time()\n",
    "Total = round((t4-t3)/60, 1)\n",
    "print('Training complete, took '+str(Total)+' minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r'U:\\Training_Data\\Training_Images\\Test\\Unet_Test'\n",
    "ids = next(os.walk(train_path))[2] # list of names all images in the given path\n",
    "for i in ids:\n",
    "    if '.xml' in i:\n",
    "        ids.remove(i)\n",
    "\n",
    "try:\n",
    "    ids.remove('Thumbs.db')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"No. of images = \", len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_list = [0,9,1,2,3,4,5,6,7,8,10,19,11,12,13,14,15,16,17,18,20,29,21,22,23,24,25,26,27,28,\n",
    "             30,39,31,32,33,34,35,36,37,38,40,49,41,42,43,44,45,46,47,48,50,59,51,52,53,54,55,56,57,58,\n",
    "             60,69,61,62,63,64,65,66,67,68,70,79,71,72,73,74,75,76,77,78,80,89,81,82,83,84,85,86,87,88,\n",
    "             90,99,91,92,93,94,95,96,97,98]\n",
    "\n",
    "new_ids = [ids[i] for i in fixed_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.zeros((len(ids), im_height, im_width, 4), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm is used to display the progress bar\n",
    "import os\n",
    "os.chdir(r'U:\\Training_Data\\Training_Images\\Test\\Unet_Test')\n",
    "for n, id_ in tqdm_notebook(enumerate(new_ids), total=len(new_ids)):\n",
    "    # Load images\n",
    "    img = load_img(id_)\n",
    "    x_img = img_to_array(img)\n",
    "    #x_img = gdal_array.LoadFile(id_)\n",
    "    x_img = resize(x_img, (im_height, im_width, 4), mode = 'edge', preserve_range = True)\n",
    "    X_test[n] = x_img/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(r'U:\\Training_Data\\CNN_Models\\Model_117_whole.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'U:\\Training_Data\\CNN_Models\\Model_117_whole.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = time.time()\n",
    "result = model.predict(X_test,batch_size=4)\n",
    "t4 = time.time()\n",
    "Total = round((t4-t3)/60, 1)\n",
    "print('Predictions complete, took '+str(Total)+' minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize any randome image along with the mask\n",
    "ix = random.randint(0, 99)\n",
    "print(ix)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 15))\n",
    "\n",
    "ax1.imshow(X_test[ix, ..., 0], cmap = 'gray', interpolation = 'bilinear')\n",
    "ax1.set_title('Image')\n",
    "\n",
    "ax2.imshow(result[ix].squeeze(), cmap = 'gray', interpolation = 'nearest')\n",
    "ax2.set_title('Mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_new = result*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "os.chdir(r'U:\\Training_Data\\Training_Images\\Test\\Unet_Test\\Result_Mask')\n",
    "height = 5490\n",
    "width = 5490\n",
    "tilesize = 549\n",
    "\n",
    "for i,k in enumerate(new_ids):\n",
    "    x_img = cv2.resize(result_new[i].astype('float32'), (549, 549))\n",
    "    cv2.imwrite(str(k),x_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'U:\\Training_Data\\Training_Images\\Test\\Unet_Test\\Result_Mask')\n",
    "\n",
    "img_list = glob.glob('*.png')\n",
    "\n",
    "gdal.Warp(destNameOrDestDS='test.tif',\n",
    "          srcDSOrSrcDSTab=img_list,\n",
    "          resampleAlg='near',\n",
    "          width=5490,\n",
    "          height=5490,\n",
    "          format='GTiff',\n",
    "          outputType=gdal.GDT_Byte\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE THIS FOR RASTER CALCULATIONS\n",
    "\n",
    "gdal_path = r'C:\\Users\\jbrown\\AppData\\Local\\conda\\conda\\envs\\gpu\\Scripts'\n",
    "gdal_calc_path = os.path.join(gdal_path, 'gdal_calc.py')\n",
    "\n",
    "# Arguements.\n",
    "input_file_path = 'test.tif'\n",
    "output_file_path = 'test_filtered.tif'\n",
    "calc_expr = '\"A>=5.0\"'\n",
    "nodata = '0'\n",
    "typeof = '\"Byte\"'\n",
    "\n",
    "# Generate string of process.\n",
    "gdal_calc_str = 'python {0} -A {1} --outfile={2} --calc={3} --NoDataValue={4} --type={5}'\n",
    "gdal_calc_process = gdal_calc_str.format(gdal_calc_path, input_file_path, \n",
    "    output_file_path, calc_expr, nodata, typeof)\n",
    "\n",
    "# Call process.\n",
    "os.system(gdal_calc_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'U:\\Training_Data\\Training_Images\\Test\\Unet_Test\\Result_Mask')\n",
    "sys.path.append(r'C:\\Users\\jbrown\\AppData\\Local\\conda\\conda\\envs\\gpu\\Scripts')\n",
    "gm = os.path.join('C:\\\\','Users','jbrown','AppData','Local','conda','conda','envs','neural2','Scripts','gdal_sieve.py')\n",
    "sieve_command = [\"python\", gm,'-st','10','-8','-nomask','-of','GTiff','test_filtered.tif','_sieved.tif']\n",
    "subprocess.call(sieve_command,shell=True)\n",
    "\n",
    "gm = os.path.join('C:\\\\','Users','jbrown','AppData','Local','conda','conda','envs','gpu','Scripts','gdal_proximity.py')\n",
    "prox_command = [\"python\", gm, '-of','GTiff','-ot','Byte','-distunits','PIXEL','-maxdist','8','-ot','Byte','-fixed-buf-val','1.0','_sieved.tif','_prox.tif']\n",
    "subprocess.call(prox_command,shell=True)\n",
    "\n",
    "\n",
    "sys.path.append(r'C:\\Users\\jbrown\\AppData\\Local\\conda\\conda\\envs\\gpu\\Scripts')\n",
    "gm = os.path.join('C:\\\\','Users','jbrown','AppData','Local','conda','conda','envs','gpu','Scripts','gdal_calc.py')\n",
    "calc_command = [\"python\", gm,'--calc','A+B','-A','_prox.tif','-B','_sieved.tif','--NoDataValue','255','--outfile','final_test.tif',]\n",
    "subprocess.call(calc_command,shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
